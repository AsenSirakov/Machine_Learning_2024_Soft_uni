{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb1011d-0165-4e39-a970-66e83ad9fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting churn rate across categorical features\n",
    "plt.figure(figsize=(15, 25))\n",
    "\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    plt.subplot(6, 3, i)\n",
    "    churn_rate = data.groupby(col)['churn'].value_counts(normalize=True).unstack()['Yes']\n",
    "    churn_rate.plot(kind='bar', color='salmon', edgecolor='black')\n",
    "    plt.title(f'Churn Rate in {col.capitalize()}')\n",
    "    plt.ylabel('Churn Rate')\n",
    "    plt.xlabel(col.capitalize())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da35b61-c41b-4eab-bcd3-5bdd41e646b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e0acfc-9289-4996-b35a-bbf27e30c562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4206, 30)\n",
      "Validation set shape: (1402, 30)\n",
      "Test set shape: (1402, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleaned_data_telecom.csv')  # Update path if needed\n",
    "\n",
    "# Define the feature columns and target column\n",
    "features = data.columns.drop('churn')\n",
    "target = 'churn'\n",
    "\n",
    "# Step 1: Split the data into training (60%), validation (20%), and testing (20%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data[features], data[target], test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Define categorical and numerical features\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Step 2: Define separate transformers for each set\n",
    "# Transformer for training set\n",
    "train_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)])\n",
    "\n",
    "# Transformer for validation set\n",
    "val_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)])\n",
    "\n",
    "# Transformer for test set\n",
    "test_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)])\n",
    "\n",
    "# Step 3: Fit each preprocessor only on its respective set and transform\n",
    "X_train_preprocessed = train_preprocessor.fit_transform(X_train)\n",
    "X_val_preprocessed = val_preprocessor.fit_transform(X_val)\n",
    "X_test_preprocessed = test_preprocessor.fit_transform(X_test)\n",
    "\n",
    "# Display shapes of the preprocessed sets to confirm successful transformation\n",
    "print(\"Training set shape:\", X_train_preprocessed.shape)\n",
    "print(\"Validation set shape:\", X_val_preprocessed.shape)\n",
    "print(\"Test set shape:\", X_test_preprocessed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cbc30c2-829d-4d1c-ac76-1240b6ce9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_data_telecom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820ff97d-11e0-498e-83ec-633c8f63d9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4206, 30)\n",
      "Validation set shape: (1402, 30)\n",
      "Test set shape: (1402, 30)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def preprocess_and_split_data(df, target_column, test_size=0.4, val_size=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Split the data into training, validation, and testing sets, and preprocess each set with scaling and encoding.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataset to split and preprocess.\n",
    "    target_column (str): The name of the target column.\n",
    "    test_size (float): The proportion of data to include in the test + validation sets.\n",
    "    val_size (float): The proportion of the remaining data (test + validation) to allocate to validation.\n",
    "    random_state (int): Seed for random splitting.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Preprocessed training, validation, and test sets (X_train, X_val, X_test, y_train, y_val, y_test).\n",
    "    \"\"\"\n",
    "    # Step 1: Define features and split the data\n",
    "    features = df.columns.drop(target_column)\n",
    "    X = df[features]\n",
    "    y = df[target_column]\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_size, random_state=random_state)\n",
    "    \n",
    "    # Step 2: Identify categorical and numerical features\n",
    "    categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Step 3: Define and apply transformers for each set\n",
    "    train_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)])\n",
    "    \n",
    "    val_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)])\n",
    "    \n",
    "    test_preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_features)])\n",
    "    \n",
    "    # Fit each preprocessor only on its respective set and transform\n",
    "    X_train_preprocessed = train_preprocessor.fit_transform(X_train)\n",
    "    X_val_preprocessed = val_preprocessor.fit_transform(X_val)\n",
    "    X_test_preprocessed = test_preprocessor.fit_transform(X_test)\n",
    "    \n",
    "    # Display shapes of the preprocessed sets to confirm successful transformation\n",
    "    print(\"Training set shape:\", X_train_preprocessed.shape)\n",
    "    print(\"Validation set shape:\", X_val_preprocessed.shape)\n",
    "    print(\"Test set shape:\", X_test_preprocessed.shape)\n",
    "    \n",
    "    return X_train_preprocessed, X_val_preprocessed, X_test_preprocessed, y_train, y_val, y_test\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `data` is your DataFrame and 'churn' is the target column\n",
    "X_train_preprocessed, X_val_preprocessed, X_test_preprocessed, y_train, y_val, y_test = preprocess_and_split_data(data, target_column='churn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b864426f-1b45-45ee-bdca-3c138805eab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Coefficients:\n",
      "                                        Feature  Coefficient\n",
      "1                                   num__tenure    -1.479676\n",
      "25                       cat__contract_Two year    -1.385469\n",
      "3                            num__total_charges     0.763472\n",
      "10            cat__internet_service_Fiber optic     0.745609\n",
      "24                       cat__contract_One year    -0.682765\n",
      "7                        cat__phone_service_Yes    -0.496263\n",
      "13                     cat__online_security_Yes    -0.412952\n",
      "9                       cat__multiple_lines_Yes     0.357369\n",
      "26                   cat__paperless_billing_Yes     0.346578\n",
      "19                        cat__tech_support_Yes    -0.288973\n",
      "23                    cat__streaming_movies_Yes     0.211951\n",
      "6                           cat__dependents_Yes    -0.210361\n",
      "27  cat__payment_method_Credit card (automatic)    -0.196227\n",
      "21                       cat__streaming_t_v_Yes     0.193864\n",
      "28         cat__payment_method_Electronic check     0.141083\n",
      "2                          num__monthly_charges    -0.137858\n",
      "22    cat__streaming_movies_No internet service    -0.136263\n",
      "20       cat__streaming_t_v_No internet service    -0.136263\n",
      "12     cat__online_security_No internet service    -0.136263\n",
      "18        cat__tech_support_No internet service    -0.136263\n",
      "16   cat__device_protection_No internet service    -0.136263\n",
      "14       cat__online_backup_No internet service    -0.136263\n",
      "11                     cat__internet_service_No    -0.136263\n",
      "29             cat__payment_method_Mailed check    -0.131703\n",
      "8          cat__multiple_lines_No phone service     0.106375\n",
      "15                       cat__online_backup_Yes    -0.071621\n",
      "4                              cat__gender_Male     0.057462\n",
      "0                           num__senior_citizen     0.025421\n",
      "17                   cat__device_protection_Yes     0.019553\n",
      "5                              cat__partner_Yes     0.017177\n",
      "\n",
      "Validation Accuracy: 82.24%\n",
      "\n",
      "Validation Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.85      0.92      0.88      1037\n",
      "         Yes       0.71      0.54      0.61       365\n",
      "\n",
      "    accuracy                           0.82      1402\n",
      "   macro avg       0.78      0.73      0.75      1402\n",
      "weighted avg       0.81      0.82      0.81      1402\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model on the preprocessed training set\n",
    "log_reg.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Extract and display coefficients with feature names\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': train_preprocessor.get_feature_names_out(),\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "})\n",
    "\n",
    "# Sort coefficients by their absolute value to see the most influential features\n",
    "coefficients['Abs_Coefficient'] = coefficients['Coefficient'].abs()\n",
    "coefficients = coefficients.sort_values(by='Abs_Coefficient', ascending=False).drop(columns=['Abs_Coefficient'])\n",
    "\n",
    "print(\"\\nLogistic Regression Coefficients:\")\n",
    "print(coefficients)\n",
    "\n",
    "# Validate the model on the validation set (optional)\n",
    "y_val_pred = log_reg.predict(X_val_preprocessed)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(\"\\nValidation Set Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0462c-e4a7-4339-ac70-b5701043f499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Filter data for customers with tenure <= 1 month\n",
    "short_term_customers = data[data['tenure'] <= 1].copy()\n",
    "\n",
    "# Step 2: Define features and target variable\n",
    "features = ['contract', 'internet_service', 'online_security', 'tech_support', \n",
    "            'streaming_t_v', 'payment_method']  # Add relevant features\n",
    "target = 'churn'\n",
    "\n",
    "# Convert categorical features using one-hot encoding\n",
    "short_term_customers_encoded = pd.get_dummies(short_term_customers[features], drop_first=True)\n",
    "X = short_term_customers_encoded\n",
    "y = short_term_customers[target].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Step 3: Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Train Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Train Decision Tree model\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate Logistic Regression on validation set\n",
    "y_val_pred_log_reg = log_reg.predict(X_val)\n",
    "log_reg_accuracy = accuracy_score(y_val, y_val_pred_log_reg)\n",
    "print(f\"Logistic Regression Validation Accuracy: {log_reg_accuracy * 100:.2f}%\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_log_reg))\n",
    "\n",
    "# Step 5: Evaluate Decision Tree on validation set\n",
    "y_val_pred_tree = tree_clf.predict(X_val)\n",
    "tree_accuracy = accuracy_score(y_val, y_val_pred_tree)\n",
    "print(f\"Decision Tree Validation Accuracy: {tree_accuracy * 100:.2f}%\")\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_tree))\n",
    "\n",
    "# Optional: Feature Importance for Decision Tree\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': tree_clf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importances from Decision Tree:\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87c49f4d-c122-4f17-ba6d-e303f4a948b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'senior_citizen', 'partner', 'dependents', 'tenure',\n",
       "       'phone_service', 'multiple_lines', 'internet_service',\n",
       "       'online_security', 'online_backup', 'device_protection', 'tech_support',\n",
       "       'streaming_t_v', 'streaming_movies', 'contract', 'paperless_billing',\n",
       "       'payment_method', 'monthly_charges', 'total_charges', 'churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90586dd0-245f-4451-8c59-fed72eb71a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Accuracy: 67.42%\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        75\n",
      "           1       0.72      0.72      0.72       103\n",
      "\n",
      "    accuracy                           0.67       178\n",
      "   macro avg       0.67      0.67      0.67       178\n",
      "weighted avg       0.67      0.67      0.67       178\n",
      "\n",
      "Decision Tree Validation Accuracy: 66.29%\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.75      0.65        75\n",
      "           1       0.77      0.60      0.67       103\n",
      "\n",
      "    accuracy                           0.66       178\n",
      "   macro avg       0.67      0.67      0.66       178\n",
      "weighted avg       0.69      0.66      0.66       178\n",
      "\n",
      "\n",
      "Feature Importances from Decision Tree:\n",
      "                                   Feature  Importance\n",
      "10            internet_service_Fiber optic    0.554301\n",
      "2                          monthly_charges    0.100438\n",
      "26                   paperless_billing_Yes    0.069299\n",
      "3                            total_charges    0.066689\n",
      "8          multiple_lines_No phone service    0.054032\n",
      "21                       streaming_t_v_Yes    0.052845\n",
      "4                              gender_Male    0.047580\n",
      "27  payment_method_Credit card (automatic)    0.023829\n",
      "19                        tech_support_Yes    0.018888\n",
      "20       streaming_t_v_No internet service    0.012100\n",
      "25                       contract_Two year    0.000000\n",
      "18        tech_support_No internet service    0.000000\n",
      "24                       contract_One year    0.000000\n",
      "23                    streaming_movies_Yes    0.000000\n",
      "22    streaming_movies_No internet service    0.000000\n",
      "28         payment_method_Electronic check    0.000000\n",
      "0                           senior_citizen    0.000000\n",
      "15                       online_backup_Yes    0.000000\n",
      "17                   device_protection_Yes    0.000000\n",
      "16   device_protection_No internet service    0.000000\n",
      "1                                   tenure    0.000000\n",
      "14       online_backup_No internet service    0.000000\n",
      "13                     online_security_Yes    0.000000\n",
      "12     online_security_No internet service    0.000000\n",
      "11                     internet_service_No    0.000000\n",
      "9                       multiple_lines_Yes    0.000000\n",
      "7                        phone_service_Yes    0.000000\n",
      "6                           dependents_Yes    0.000000\n",
      "5                              partner_Yes    0.000000\n",
      "29             payment_method_Mailed check    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Step 1: Filter data for customers with tenure <= 1 month\n",
    "short_term_customers = data[data['tenure'] <= 1].copy()\n",
    "\n",
    "# Step 2: Define features and target variable\n",
    "features = ['gender', 'senior_citizen', 'partner', 'dependents', 'tenure',\n",
    "       'phone_service', 'multiple_lines', 'internet_service',\n",
    "       'online_security', 'online_backup', 'device_protection', 'tech_support',\n",
    "       'streaming_t_v', 'streaming_movies', 'contract', 'paperless_billing',\n",
    "       'payment_method', 'monthly_charges', 'total_charges']  # Add relevant features\n",
    "target = 'churn'\n",
    "\n",
    "# Convert categorical features using one-hot encoding\n",
    "short_term_customers_encoded = pd.get_dummies(short_term_customers[features], drop_first=True)\n",
    "X = short_term_customers_encoded\n",
    "y = short_term_customers[target].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# Step 3: Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 4: Train Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Train Decision Tree model\n",
    "tree_clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate Logistic Regression on validation set\n",
    "y_val_pred_log_reg = log_reg.predict(X_val)\n",
    "log_reg_accuracy = accuracy_score(y_val, y_val_pred_log_reg)\n",
    "print(f\"Logistic Regression Validation Accuracy: {log_reg_accuracy * 100:.2f}%\")\n",
    "print(\"\\nLogistic Regression Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_log_reg))\n",
    "\n",
    "# Step 5: Evaluate Decision Tree on validation set\n",
    "y_val_pred_tree = tree_clf.predict(X_val)\n",
    "tree_accuracy = accuracy_score(y_val, y_val_pred_tree)\n",
    "print(f\"Decision Tree Validation Accuracy: {tree_accuracy * 100:.2f}%\")\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred_tree))\n",
    "\n",
    "# Optional: Feature Importance for Decision Tree\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': tree_clf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(\"\\nFeature Importances from Decision Tree:\")\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cf2713-45c4-4eed-b196-ffec1a308150",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
